{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_prediction_lstm_attention_dot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RVPzEmB5fVW",
        "outputId": "70e7f70f-170d-48bd-878a-7798e8823541"
      },
      "source": [
        "! pip install attention"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: attention in /usr/local/lib/python3.7/dist-packages (4.0)\n",
            "Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.7/dist-packages (from attention) (2.6.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from attention) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.12.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.6.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.6.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (2.6.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (0.37.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.41.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1->attention) (1.12.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.1->attention) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1->attention) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1->attention) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1->attention) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1->attention) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1->attention) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1->attention) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1->attention) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlANetNK7FAH",
        "outputId": "f9b52500-1f68-405d-befc-e2b8cc0ef974"
      },
      "source": [
        "# installation\n",
        "! pip install yfinance --upgrade --no-cache-dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.64)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Requirement already satisfied: lxml>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.6.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvS9sFni71Ja",
        "outputId": "7201f32a-d6de-413a-b123-f84d7f4f28d2"
      },
      "source": [
        "import yfinance as yf\n",
        "\n",
        "msft = yf.Ticker(\"MSFT\")\n",
        "\n",
        "# get stock info\n",
        "msft.info\n",
        "\n",
        "# get historical market data\n",
        "hist = msft.history(period=\"max\")\n",
        "print(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                  Open        High  ...  Dividends  Stock Splits\n",
            "Date                                ...                         \n",
            "1986-03-13    0.056001    0.064236  ...        0.0           0.0\n",
            "1986-03-14    0.061491    0.064785  ...        0.0           0.0\n",
            "1986-03-17    0.063687    0.065334  ...        0.0           0.0\n",
            "1986-03-18    0.064785    0.065334  ...        0.0           0.0\n",
            "1986-03-19    0.063138    0.063687  ...        0.0           0.0\n",
            "...                ...         ...  ...        ...           ...\n",
            "2021-11-01  331.359985  331.489990  ...        0.0           0.0\n",
            "2021-11-02  330.309998  333.450012  ...        0.0           0.0\n",
            "2021-11-03  333.899994  334.899994  ...        0.0           0.0\n",
            "2021-11-04  332.890015  336.540009  ...        0.0           0.0\n",
            "2021-11-05  338.510010  338.790009  ...        0.0           0.0\n",
            "\n",
            "[8988 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0esDR2B76BJ",
        "outputId": "894ad9e1-39fa-4fb9-a071-246d1a1ed0a7"
      },
      "source": [
        "type(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZVA5p6S78H_",
        "outputId": "f335fa74-33b9-4a6d-cca7-9c2019228998"
      },
      "source": [
        "hist.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'], dtype='object')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dajigHnj79wi",
        "outputId": "0e1210b6-eb56-41da-cd8a-1a370d92978d"
      },
      "source": [
        "# download ticker data from nasdaq, manually extracted \n",
        "import urllib.request\n",
        "url = 'https://gitlab.com/brainekt_ai/us-stock-ticker/-/raw/main/nasdaq_screener_1635374155108.csv'\n",
        "filename = 'nasdaq_screener_1635374155108.csv'\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('nasdaq_screener_1635374155108.csv',\n",
              " <http.client.HTTPMessage at 0x7fa3981b3650>)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCpwgIEX8ARD",
        "outputId": "e1f83ef9-28c4-494f-8d6f-8e4cf424a608"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nasdaq_screener_1635374155108.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViYgFBSC8CmD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "tickers = pd.read_csv(\"nasdaq_screener_1635374155108.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "Rqq1pX2_8EoW",
        "outputId": "01a61fcf-a887-4825-fabb-a99ecce03c6b"
      },
      "source": [
        "tickers.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Name</th>\n",
              "      <th>Last Sale</th>\n",
              "      <th>Net Change</th>\n",
              "      <th>% Change</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>Country</th>\n",
              "      <th>IPO Year</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AACG</td>\n",
              "      <td>ATA Creativity Global American Depositary Shares</td>\n",
              "      <td>$2.28</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-2.564%</td>\n",
              "      <td>7.153938e+07</td>\n",
              "      <td>China</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75873</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>Service to the Health Industry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AACIU</td>\n",
              "      <td>Armada Acquisition Corp. I Unit</td>\n",
              "      <td>$9.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>United States</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AADI</td>\n",
              "      <td>Aadi Bioscience Inc. Common Stock</td>\n",
              "      <td>$27.03</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.446%</td>\n",
              "      <td>5.640983e+08</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33626</td>\n",
              "      <td>Health Care</td>\n",
              "      <td>Biotechnology: Pharmaceutical Preparations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAL</td>\n",
              "      <td>American Airlines Group Inc. Common Stock</td>\n",
              "      <td>$19.03</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-1.857%</td>\n",
              "      <td>1.232220e+10</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22076823</td>\n",
              "      <td>Transportation</td>\n",
              "      <td>Air Freight/Delivery Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAME</td>\n",
              "      <td>Atlantic American Corporation Common Stock</td>\n",
              "      <td>$3.98</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-2.451%</td>\n",
              "      <td>8.123484e+07</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14868</td>\n",
              "      <td>Finance</td>\n",
              "      <td>Life Insurance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Symbol  ...                                    Industry\n",
              "0   AACG  ...              Service to the Health Industry\n",
              "1  AACIU  ...                                         NaN\n",
              "2   AADI  ...  Biotechnology: Pharmaceutical Preparations\n",
              "3    AAL  ...               Air Freight/Delivery Services\n",
              "4   AAME  ...                              Life Insurance\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9o9VEvu8GaK"
      },
      "source": [
        "tickers_ls = list(tickers[\"Symbol\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsOBngpg8IJL"
      },
      "source": [
        "# utils code\n",
        "# assist\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "## Data Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.externals import joblib \n",
        "\n",
        "\n",
        "#### DATA CREATION FUNCTIONS ####\n",
        "def create_data(file_list):\n",
        "    \"\"\"\n",
        "    Utility function to create a dataset from a filelist.\n",
        "    \"\"\"\n",
        "    counter = 1\n",
        "    df_list = pd.DataFrame()\n",
        "    for file in file_list:\n",
        "        if (os.stat(file).st_size != 0):\n",
        "            df = pd.read_csv(file, sep = \",\")\n",
        "            df['symbol'] = file\n",
        "            df_list = df_list.append(df)\n",
        "            print (counter, \" out of \", len(file_list))\n",
        "            counter += 1\n",
        "    return pd.DataFrame(df_list)\n",
        "\n",
        "\n",
        "def fetch_data():\n",
        "    \"\"\"\n",
        "    Get the files from the data folder. \n",
        "    \"\"\"\n",
        "    main_dir = os.getcwd()\n",
        "    # STOCKS\n",
        "    os.chdir(main_dir)\n",
        "    os.chdir(\"./data/Stocks\")\n",
        "    stock_list = os.listdir()\n",
        "    stocks = create_data(stock_list)\n",
        "    #ETFs\n",
        "    os.chdir(main_dir)\n",
        "    os.chdir(\"./data/ETFs\")\n",
        "    etf_list = os.listdir()\n",
        "    etf = create_data(etf_list)\n",
        "\n",
        "    return stocks, etf\n",
        "\n",
        "\n",
        "#### DATA PROCESSING FUNCTIONS ####\n",
        "def scale_df(data, model_name):\n",
        "    \"\"\"\n",
        "    This class takes in a pandas dataframe and generates \n",
        "    the normalized version of it\n",
        "    \"\"\"\n",
        "    # scales the data\n",
        "    scaler = MinMaxScaler()\n",
        "    df = scaler.fit_transform(data)\n",
        "    \n",
        "    return df, scaler\n",
        "\n",
        "\n",
        "def generate_ta(data):\n",
        "    \"\"\"\n",
        "    Runs ta on a dataset and saves to csv.\n",
        "    \"\"\"\n",
        "    # converts data into ta dataframe\n",
        "    df = add_all_ta_features(data, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=True)\n",
        "    df.to_csv(\"../data/df_ta.csv\")\n",
        "    \n",
        "\n",
        "def build_window(df, look_back, n_features):\n",
        "    \"\"\"\n",
        "    Builds sliding windows to shift the batch by 1 step at a time\n",
        "    \"\"\"\n",
        "    x_train = [] # This list contain the sequences to predict when training\n",
        "    y_train = [] # This list contain the next value of the sequences when training\n",
        "\n",
        "    for i in range(look_back, df.shape[0]):\n",
        "        x_train.append(df[i-look_back:i,0:n_features].tolist()) # ,0 used in order to return the values only\n",
        "        y_train.append(df[i,0].tolist()) # tolist() converts np array to simple array\n",
        "   \n",
        "    # Converting arrays from lists to np arrays. \n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    # Rounding numbers to speed up training.\n",
        "    x_train = np.round(x_train, 5)\n",
        "    y_train = np.round(y_train, 5)\n",
        "\n",
        "    return x_train, y_train\n",
        "\n",
        "\n",
        "def trim_dataset(mat, batch_size):\n",
        "    \"\"\"\n",
        "    trims dataset to a size that's divisible by the batch size\n",
        "    \"\"\"\n",
        "\n",
        "    no_of_rows_drop = mat.shape[0] % batch_size\n",
        "    if(no_of_rows_drop > 0):\n",
        "        return mat[:-no_of_rows_drop]\n",
        "    else:\n",
        "        return mat\n",
        "\n",
        "#### FINAL PIPELINE FUNCTION ####\n",
        "def preproc_pipeline(data, name):\n",
        "    \"\"\"\n",
        "    The preprocessing pipeline takes in a csv of processed data and creates\n",
        "    the training, validation, and test sets\n",
        "    \"\"\"\n",
        "    # Scale values\n",
        "    data, scaler = scale_df(data, name)\n",
        "    # Split\n",
        "    train_set, testval_set = train_test_split(data, train_size=0.6, test_size=0.4, shuffle=False)\n",
        "    validation_set, test_set = train_test_split(testval_set, train_size=0.7, test_size=0.3, shuffle=False)\n",
        "    \n",
        "    return train_set, validation_set, test_set, scaler\n",
        "\n",
        "\n",
        "def model_preproc_pipeline(data, look_back, batch_size, n_features):\n",
        "    \"\"\"\n",
        "    preprocesses data for LSTM input\n",
        "    \"\"\"\n",
        "    x_train, y_train = build_window(data, look_back, n_features)\n",
        "\n",
        "    x_train = trim_dataset(x_train, batch_size)\n",
        "    y_train = trim_dataset(y_train, batch_size)\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_features))\n",
        "    return x_train, y_train\n",
        "    \n",
        "\n",
        "def generate_dataset():\n",
        "        stocks, etf = create_data(\".\")\n",
        "        data = pd.concat([stocks, etf])\n",
        "        generate_ta(data)\n",
        "        # we have to read file\n",
        "        data = pd.read_csv(\"./df_ta.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZoyBYcK8Lde"
      },
      "source": [
        "from tensorflow import keras as keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Input, Flatten, Add, Concatenate, Dot, Multiply, Bidirectional, GaussianNoise\n",
        "from tensorflow.keras.layers import Maximum, Average, Activation\n",
        "\n",
        "from attention import Attention\n",
        "import tensorflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# attention: https://github.com/philipperemy/keras-attention-mechanism\n",
        "\n",
        "def best_lstm_model(n_features, batch_size, look_back):\n",
        "    \"\"\"\n",
        "    Returns a keras LSTM model. Our architecture will be kept \n",
        "    in this method.\n",
        "    \"\"\"\n",
        "    x_i1 = Input((TIME_STEPS, 1), name='ip1')\n",
        "    g = GaussianNoise(0.05, name='g')(x_i1)\n",
        "\n",
        "    b1 = Bidirectional(LSTM(units = 64, return_sequences = True, name='l1'), name='b1')(x_i1)\n",
        "    b1 = Bidirectional(LSTM(units = 64, return_sequences = True, name='l3'), name='b3')(b1)\n",
        "\n",
        "    b2 = Bidirectional(LSTM(units = 64, return_sequences = True, name='l2'), name='b2')(g)\n",
        "    b2 = Bidirectional(LSTM(units = 64, return_sequences = True, name='l4'), name='b4')(g)\n",
        "    \n",
        "\n",
        "    d = Add(name='add')([b1, b2])\n",
        "    a = Attention(64, name='attn')(d)\n",
        "\n",
        "    y = Dense(1)(a)\n",
        "\n",
        "    model = Model(x_i1, y)\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "   if epoch < 5:\n",
        "     return lr\n",
        "   else:\n",
        "     return lr * tensorflow.math.exp(-0.1)\n",
        "     \n",
        "\n",
        "\n",
        "def train_model(model, x_train, y_train, epochs, batch_size, lr):\n",
        "    \"\"\"\n",
        "    Takes a training dataset and a model and returns a trained model \n",
        "    after ts timesteps.\n",
        "    \"\"\"\n",
        "    callback = tensorflow.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "    model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size, callbacks=[callback])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orf5seZxNgyq"
      },
      "source": [
        "# Defining hyper parameters\n",
        "TIME_STEPS = 100\n",
        "BATCH_SIZE = 128\n",
        "N_FEATURES = 1\n",
        "lr = 0.0001 # learning rate\n",
        "EPOCHS = 5\n",
        "# result generation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIg-XxHk8PjZ"
      },
      "source": [
        "regressor = best_lstm_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSLnqZvNNcne",
        "outputId": "8f45513b-83eb-43c5-e17c-2575ac0b8adb"
      },
      "source": [
        "regressor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "ip1 (InputLayer)                [(None, 100, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "b1 (Bidirectional)              (None, 100, 128)     33792       ip1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "g (GaussianNoise)               (None, 100, 1)       0           ip1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "b3 (Bidirectional)              (None, 100, 128)     98816       b1[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "b4 (Bidirectional)              (None, 100, 128)     33792       g[0][0]                          \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 100, 128)     0           b3[0][0]                         \n",
            "                                                                 b4[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "last_hidden_state (Lambda)      (None, 128)          0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "attention_score_vec (Dense)     (None, 100, 128)     16384       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "attention_score (Dot)           (None, 100)          0           last_hidden_state[0][0]          \n",
            "                                                                 attention_score_vec[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "attention_weight (Activation)   (None, 100)          0           attention_score[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "context_vector (Dot)            (None, 128)          0           add[0][0]                        \n",
            "                                                                 attention_weight[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "attention_output (Concatenate)  (None, 256)          0           context_vector[0][0]             \n",
            "                                                                 last_hidden_state[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "attention_vector (Dense)        (None, 128)          32768       attention_output[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            129         attention_vector[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 215,681\n",
            "Trainable params: 215,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FnbnnWaVXVq"
      },
      "source": [
        "# Prediction model 1 based on George V Jose\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def predict(data, num_prediction):\n",
        "    # Scaling data\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(data)\n",
        "\n",
        "    # Looking at last TIME_STEPS value\n",
        "    prediction_list = scaled[-TIME_STEPS:]\n",
        "    \n",
        "    for _ in range(num_prediction):\n",
        "        # Looking at last TIME_STEPS value (1 of our batch)\n",
        "        x = prediction_list[-TIME_STEPS:]\n",
        "        x = np.array(x)\n",
        "        \n",
        "        # 1 batch with TIME_STEPS and 1 feature\n",
        "        x = x.reshape((1, TIME_STEPS, 1))\n",
        "        \n",
        "        # prediction\n",
        "        print(\"predicting batch \", x)\n",
        "        output = model.predict(x)[0][0]\n",
        "        \n",
        "        # Appends prediction results back into \n",
        "        prediction_list = np.append(prediction_list, output)\n",
        "        \n",
        "    prediction_list = prediction_list[TIME_STEPS - 1:]\n",
        "    \n",
        "    # Reverse the scaling\n",
        "    prediction_list = prediction_list.reshape(num_prediction+1, 1)\n",
        "    prediction_list = scaler.inverse_transform(prediction_list)\n",
        "    \n",
        "    return prediction_list\n",
        "\n",
        "# Prediction model 2 based on Ravindra Compella\n",
        "def moving_test_window_preds(data, num_predictions, TIME_STEPS, model):\n",
        "    prediction_list = []\n",
        "    \n",
        "    # Scaling data\n",
        "    scaler = MinMaxScaler()\n",
        "    data = scaler.fit_transform(data)\n",
        "    \n",
        "    moving_test_window = data[-TIME_STEPS:]\n",
        "    moving_test_window = np.array(moving_test_window)\n",
        "    \n",
        "    # Scaling data\n",
        "    # scaler = MinMaxScaler()\n",
        "    # moving_test_window = scaler.fit_transform(moving_test_window)\n",
        "    \n",
        "    # Reshaping data\n",
        "    moving_test_window = moving_test_window.reshape((1, TIME_STEPS, 1))\n",
        "    \n",
        "    for i in range(num_predictions):\n",
        "        # print(\"predicting batch \", moving_test_window)\n",
        "        preds_one_step = model.predict(moving_test_window)\n",
        "        prediction_list.append(preds_one_step[0,0])\n",
        "        preds_one_step = preds_one_step.reshape(1,1,1)\n",
        "        moving_test_window = np.concatenate((moving_test_window[:,1:,:], preds_one_step), axis=1)\n",
        "        \n",
        "    prediction_list = np.array(prediction_list)\n",
        "    prediction_list = prediction_list.reshape(num_predictions, 1)\n",
        "    prediction_list = scaler.inverse_transform(prediction_list)\n",
        "    \n",
        "    return prediction_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Sz4jhmXFnr"
      },
      "source": [
        "top_companies = ['AMZN', 'AAPL', 'NFLX', 'GOOG', 'MSFT', 'GOOGL', 'TSLA', 'CSCO', 'COST', 'FB']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPaU8tdMXHUV",
        "outputId": "b8aa40c0-064d-41b4-d963-ad52a95e987a"
      },
      "source": [
        "for i in range(len(top_companies)):\n",
        "    comp = top_companies[i]\n",
        "    comp_tick = yf.Ticker(comp)\n",
        "    # get historical market data\n",
        "    hist = comp_tick.history(period=\"max\")\n",
        "    print(f\"{comp}: {len(hist) * 0.4 * 0.3 // 2}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AMZN: 369.0\n",
            "AAPL: 618.0\n",
            "NFLX: 294.0\n",
            "GOOG: 260.0\n",
            "MSFT: 539.0\n",
            "GOOGL: 260.0\n",
            "TSLA: 171.0\n",
            "CSCO: 479.0\n",
            "COST: 534.0\n",
            "FB: 143.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJV-GLsgXJZt",
        "outputId": "71e738dc-ef4e-43d1-b057-84bcefce78be"
      },
      "source": [
        "# Defining hyper parameters\n",
        "TIME_STEPS = 100\n",
        "BATCH_SIZE = 128\n",
        "N_FEATURES = 1\n",
        "lr = 0.001 # learning rate\n",
        "EPOCHS = 10\n",
        "# result generation\n",
        "\n",
        "\n",
        "for i in range(len(top_companies)):\n",
        "    comp = top_companies[i]\n",
        "    comp_tick = yf.Ticker(comp)\n",
        "    # get historical market data\n",
        "    hist = comp_tick.history(period=\"max\")\n",
        "    # train data\n",
        "    # we only use closing price\n",
        "    data = hist.iloc[:,1:2]\n",
        "    train, valid, test, scalar = preproc_pipeline(data, False)\n",
        "    # Create windows, trim windows, and reshape for LSTM input\n",
        "    x_train, y_train = model_preproc_pipeline(train, TIME_STEPS, BATCH_SIZE, N_FEATURES)\n",
        "\n",
        "    regressor = best_lstm_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)\n",
        "\n",
        "    # train model\n",
        "    # Training the model\n",
        "    regressor = train_model(regressor, x_train, y_train, EPOCHS, BATCH_SIZE, lr)\n",
        "\n",
        "    # Preparing test and validation sets\n",
        "    df_test = trim_dataset(test, BATCH_SIZE)\n",
        "    df_val, df_testing = np.split(df_test, 2)\n",
        "\n",
        "    n_samples = len(df_testing)\n",
        "\n",
        "    unseen_predictions = moving_test_window_preds(df_val, n_samples, TIME_STEPS, regressor)\n",
        "\n",
        "    # Evaluating model for unseen data\n",
        "    mse = mean_squared_error(df_testing[:n_samples], unseen_predictions[:n_samples])\n",
        "    n_mse = mse / (df_testing[:n_samples]).mean()\n",
        "    print(f\"comp: {comp} mse: {mse} norm_mse: {n_mse}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "28/28 [==============================] - 26s 652ms/step - loss: 1.5829e-04\n",
            "Epoch 2/10\n",
            "28/28 [==============================] - 18s 640ms/step - loss: 1.5374e-05\n",
            "Epoch 3/10\n",
            "28/28 [==============================] - 18s 642ms/step - loss: 6.7767e-06\n",
            "Epoch 4/10\n",
            "28/28 [==============================] - 18s 651ms/step - loss: 3.6558e-06\n",
            "Epoch 5/10\n",
            "28/28 [==============================] - 18s 649ms/step - loss: 2.4343e-06\n",
            "Epoch 6/10\n",
            "28/28 [==============================] - 18s 651ms/step - loss: 2.1108e-06\n",
            "Epoch 7/10\n",
            "28/28 [==============================] - 18s 648ms/step - loss: 2.0406e-06\n",
            "Epoch 8/10\n",
            "28/28 [==============================] - 18s 655ms/step - loss: 1.7996e-06\n",
            "Epoch 9/10\n",
            "28/28 [==============================] - 18s 652ms/step - loss: 1.6993e-06\n",
            "Epoch 10/10\n",
            "28/28 [==============================] - 18s 646ms/step - loss: 1.6771e-06\n",
            "comp: AMZN mse: 0.175170014927676 norm_mse: 0.2188735580096118\n",
            "Epoch 1/10\n",
            "47/47 [==============================] - 39s 652ms/step - loss: 4.5181e-05\n",
            "Epoch 2/10\n",
            "47/47 [==============================] - 32s 671ms/step - loss: 1.5005e-06\n",
            "Epoch 3/10\n",
            "47/47 [==============================] - 31s 657ms/step - loss: 1.2156e-06\n",
            "Epoch 4/10\n",
            "47/47 [==============================] - 31s 653ms/step - loss: 9.8195e-07\n",
            "Epoch 5/10\n",
            "47/47 [==============================] - 31s 649ms/step - loss: 6.6771e-07\n",
            "Epoch 6/10\n",
            "47/47 [==============================] - 31s 657ms/step - loss: 3.7506e-07\n",
            "Epoch 7/10\n",
            "47/47 [==============================] - 31s 652ms/step - loss: 1.9956e-07\n",
            "Epoch 8/10\n",
            "47/47 [==============================] - 31s 651ms/step - loss: 1.5664e-07\n",
            "Epoch 9/10\n",
            "47/47 [==============================] - 31s 654ms/step - loss: 1.4110e-07\n",
            "Epoch 10/10\n",
            "47/47 [==============================] - 31s 652ms/step - loss: 1.3506e-07\n",
            "comp: AAPL mse: 0.1509098582634488 norm_mse: 0.2652021022604571\n",
            "Epoch 1/10\n",
            "22/22 [==============================] - 21s 654ms/step - loss: 1.4850e-04\n",
            "Epoch 2/10\n",
            "22/22 [==============================] - 14s 650ms/step - loss: 2.3735e-05\n",
            "Epoch 3/10\n",
            "22/22 [==============================] - 14s 652ms/step - loss: 7.4989e-06\n",
            "Epoch 4/10\n",
            "22/22 [==============================] - 14s 658ms/step - loss: 3.8866e-06\n",
            "Epoch 5/10\n",
            "22/22 [==============================] - 15s 661ms/step - loss: 3.1793e-06\n",
            "Epoch 6/10\n",
            "22/22 [==============================] - 14s 657ms/step - loss: 2.6233e-06\n",
            "Epoch 7/10\n",
            "22/22 [==============================] - 14s 657ms/step - loss: 2.7373e-06\n",
            "Epoch 8/10\n",
            "22/22 [==============================] - 14s 659ms/step - loss: 2.7214e-06\n",
            "Epoch 9/10\n",
            "22/22 [==============================] - 15s 666ms/step - loss: 2.4108e-06\n",
            "Epoch 10/10\n",
            "22/22 [==============================] - 14s 657ms/step - loss: 2.3078e-06\n",
            "comp: NFLX mse: 0.08133008431080932 norm_mse: 0.10807957674840443\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 20s 645ms/step - loss: 6.9802e-04\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 12s 639ms/step - loss: 1.1468e-04\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 12s 640ms/step - loss: 6.6958e-05\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 12s 646ms/step - loss: 4.7177e-05\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 12s 642ms/step - loss: 3.1850e-05\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 12s 640ms/step - loss: 2.3243e-05\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 12s 642ms/step - loss: 1.9852e-05\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 12s 639ms/step - loss: 1.7458e-05\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 12s 636ms/step - loss: 1.6246e-05\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 1.5487e-05\n",
            "comp: GOOG mse: 0.08171771480503971 norm_mse: 0.10767618324347268\n",
            "Epoch 1/10\n",
            "41/41 [==============================] - 34s 654ms/step - loss: 1.7328e-04\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 27s 654ms/step - loss: 1.8825e-05\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 27s 660ms/step - loss: 8.8578e-06\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 27s 651ms/step - loss: 5.1697e-06\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 27s 659ms/step - loss: 4.6330e-06\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 27s 651ms/step - loss: 4.0217e-06\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 27s 654ms/step - loss: 3.5446e-06\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 27s 649ms/step - loss: 3.6676e-06\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 27s 650ms/step - loss: 3.2200e-06\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 27s 650ms/step - loss: 3.0212e-06\n",
            "comp: MSFT mse: 0.13179036711091002 norm_mse: 0.22125475883187737\n",
            "Epoch 1/10\n",
            "19/19 [==============================] - 20s 639ms/step - loss: 0.0013\n",
            "Epoch 2/10\n",
            "19/19 [==============================] - 12s 638ms/step - loss: 1.9314e-04\n",
            "Epoch 3/10\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 9.1955e-05\n",
            "Epoch 4/10\n",
            "19/19 [==============================] - 12s 633ms/step - loss: 6.8319e-05\n",
            "Epoch 5/10\n",
            "19/19 [==============================] - 12s 645ms/step - loss: 5.4670e-05\n",
            "Epoch 6/10\n",
            "19/19 [==============================] - 12s 642ms/step - loss: 4.5635e-05\n",
            "Epoch 7/10\n",
            "19/19 [==============================] - 12s 638ms/step - loss: 3.7770e-05\n",
            "Epoch 8/10\n",
            "19/19 [==============================] - 12s 637ms/step - loss: 3.1285e-05\n",
            "Epoch 9/10\n",
            "19/19 [==============================] - 12s 642ms/step - loss: 2.6222e-05\n",
            "Epoch 10/10\n",
            "19/19 [==============================] - 12s 643ms/step - loss: 2.2487e-05\n",
            "comp: GOOGL mse: 0.06398136587243544 norm_mse: 0.08510219305922628\n",
            "Epoch 1/10\n",
            "12/12 [==============================] - 16s 640ms/step - loss: 2.6338e-04\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 8s 645ms/step - loss: 4.2673e-05\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 8s 639ms/step - loss: 2.3781e-05\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 8s 631ms/step - loss: 1.5801e-05\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 8s 645ms/step - loss: 1.1470e-05\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 8.7915e-06\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 8s 635ms/step - loss: 6.2867e-06\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 8s 649ms/step - loss: 4.8968e-06\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 8s 638ms/step - loss: 3.8896e-06\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 8s 658ms/step - loss: 3.5330e-06\n",
            "comp: TSLA mse: 0.05321920064117358 norm_mse: 0.09254170594311195\n",
            "Epoch 1/10\n",
            "36/36 [==============================] - 31s 653ms/step - loss: 0.0053\n",
            "Epoch 2/10\n",
            "36/36 [==============================] - 23s 651ms/step - loss: 5.5119e-04\n",
            "Epoch 3/10\n",
            "36/36 [==============================] - 24s 658ms/step - loss: 2.8928e-04\n",
            "Epoch 4/10\n",
            "36/36 [==============================] - 23s 650ms/step - loss: 2.6779e-04\n",
            "Epoch 5/10\n",
            "36/36 [==============================] - 24s 656ms/step - loss: 2.3711e-04\n",
            "Epoch 6/10\n",
            "36/36 [==============================] - 26s 716ms/step - loss: 2.2158e-04\n",
            "Epoch 7/10\n",
            "36/36 [==============================] - 23s 651ms/step - loss: 2.1029e-04\n",
            "Epoch 8/10\n",
            "36/36 [==============================] - 24s 655ms/step - loss: 2.0421e-04\n",
            "Epoch 9/10\n",
            "36/36 [==============================] - 24s 655ms/step - loss: 1.8800e-04\n",
            "Epoch 10/10\n",
            "36/36 [==============================] - 24s 659ms/step - loss: 1.7805e-04\n",
            "comp: CSCO mse: 0.015350666394502851 norm_mse: 0.02058147886489378\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 33s 653ms/step - loss: 1.3573e-04\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 26s 654ms/step - loss: 1.4247e-05\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 26s 656ms/step - loss: 7.0953e-06\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 26s 653ms/step - loss: 4.4663e-06\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 26s 648ms/step - loss: 3.5264e-06\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 26s 647ms/step - loss: 3.1749e-06\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 26s 647ms/step - loss: 2.8080e-06\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 26s 646ms/step - loss: 2.7994e-06\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 26s 646ms/step - loss: 3.0007e-06\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 26s 647ms/step - loss: 2.7209e-06\n",
            "comp: COST mse: 0.09169227215321488 norm_mse: 0.1429695461324688\n",
            "Epoch 1/10\n",
            "10/10 [==============================] - 14s 655ms/step - loss: 0.0112\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 6s 650ms/step - loss: 0.0018\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 6s 645ms/step - loss: 5.4239e-04\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 6s 646ms/step - loss: 2.9671e-04\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 6s 646ms/step - loss: 2.3579e-04\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 6s 646ms/step - loss: 1.8988e-04\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 6s 650ms/step - loss: 1.7583e-04\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 7s 652ms/step - loss: 1.6280e-04\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 6s 647ms/step - loss: 1.6099e-04\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 7s 655ms/step - loss: 1.6427e-04\n",
            "comp: FB mse: 0.03524136425555034 norm_mse: 0.039964519896598924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzlNWETaYUR1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}