{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stock_prediction_baseline_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlUJxJuCRjEH",
        "outputId": "4f29d2dc-d05a-4250-e5f9-d71eec136ee0"
      },
      "source": [
        "# installation\n",
        "! pip install yfinance --upgrade --no-cache-dir"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.64.tar.gz (26 kB)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "  Downloading lxml-4.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.64-py2.py3-none-any.whl size=24109 sha256=f6be45c74ae8c2948e9d420bc0dac72364d3136d13e8be133f5a485307a0989b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4ihbongm/wheels/86/fe/9b/a4d3d78796b699e37065e5b6c27b75cff448ddb8b24943c288\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.4 yfinance-0.1.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c7OxsZrSjez",
        "outputId": "04e99082-82f3-4553-c93f-dba02567e14a"
      },
      "source": [
        "import yfinance as yf\n",
        "\n",
        "msft = yf.Ticker(\"MSFT\")\n",
        "\n",
        "# get stock info\n",
        "msft.info\n",
        "\n",
        "# get historical market data\n",
        "hist = msft.history(period=\"max\")\n",
        "print(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  Open        High  ...  Dividends  Stock Splits\n",
            "Date                                ...                         \n",
            "1986-03-13    0.056001    0.064236  ...        0.0           0.0\n",
            "1986-03-14    0.061491    0.064785  ...        0.0           0.0\n",
            "1986-03-17    0.063687    0.065334  ...        0.0           0.0\n",
            "1986-03-18    0.064785    0.065334  ...        0.0           0.0\n",
            "1986-03-19    0.063138    0.063687  ...        0.0           0.0\n",
            "...                ...         ...  ...        ...           ...\n",
            "2021-11-01  331.359985  331.489990  ...        0.0           0.0\n",
            "2021-11-02  330.309998  333.450012  ...        0.0           0.0\n",
            "2021-11-03  333.899994  334.899994  ...        0.0           0.0\n",
            "2021-11-04  332.890015  336.540009  ...        0.0           0.0\n",
            "2021-11-05  338.510010  338.790009  ...        0.0           0.0\n",
            "\n",
            "[8988 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbpBvSIxSsbt",
        "outputId": "fad19bdd-9bf7-4634-c991-b1d5f638990a"
      },
      "source": [
        "type(hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZTwkQkVSuKO",
        "outputId": "020608c9-54ca-4cf9-ef90-88e75e0718c2"
      },
      "source": [
        "hist.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-l5lld2Svxh"
      },
      "source": [
        "# we will only use closing price as our target signal, while other prices as additional features if needed\n",
        "# https://analyzingalpha.com/open-high-low-close-stocks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9O9T9UGUN4w",
        "outputId": "943787fc-f742-4d06-abd6-0ff2b8464b4b"
      },
      "source": [
        "# download ticker data from nasdaq, manually extracted \n",
        "import urllib.request\n",
        "url = 'https://gitlab.com/brainekt_ai/us-stock-ticker/-/raw/main/nasdaq_screener_1635374155108.csv'\n",
        "filename = 'nasdaq_screener_1635374155108.csv'\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('nasdaq_screener_1635374155108.csv',\n",
              " <http.client.HTTPMessage at 0x7f2ac7e0ad90>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH3Q3DMiUQj1",
        "outputId": "1b3aa7bb-75d3-4a43-81d9-fe4822d86c82"
      },
      "source": [
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nasdaq_screener_1635374155108.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyv-SVEIUSkr"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "tickers = pd.read_csv(\"nasdaq_screener_1635374155108.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2ImiF2ixUUTN",
        "outputId": "633ab59f-4a63-4039-d865-f39cb1e429f2"
      },
      "source": [
        "tickers.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Name</th>\n",
              "      <th>Last Sale</th>\n",
              "      <th>Net Change</th>\n",
              "      <th>% Change</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>Country</th>\n",
              "      <th>IPO Year</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Sector</th>\n",
              "      <th>Industry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AACG</td>\n",
              "      <td>ATA Creativity Global American Depositary Shares</td>\n",
              "      <td>$2.28</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-2.564%</td>\n",
              "      <td>7.153938e+07</td>\n",
              "      <td>China</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75873</td>\n",
              "      <td>Miscellaneous</td>\n",
              "      <td>Service to the Health Industry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AACIU</td>\n",
              "      <td>Armada Acquisition Corp. I Unit</td>\n",
              "      <td>$9.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00%</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>United States</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AADI</td>\n",
              "      <td>Aadi Bioscience Inc. Common Stock</td>\n",
              "      <td>$27.03</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.446%</td>\n",
              "      <td>5.640983e+08</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33626</td>\n",
              "      <td>Health Care</td>\n",
              "      <td>Biotechnology: Pharmaceutical Preparations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAL</td>\n",
              "      <td>American Airlines Group Inc. Common Stock</td>\n",
              "      <td>$19.03</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-1.857%</td>\n",
              "      <td>1.232220e+10</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22076823</td>\n",
              "      <td>Transportation</td>\n",
              "      <td>Air Freight/Delivery Services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAME</td>\n",
              "      <td>Atlantic American Corporation Common Stock</td>\n",
              "      <td>$3.98</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-2.451%</td>\n",
              "      <td>8.123484e+07</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14868</td>\n",
              "      <td>Finance</td>\n",
              "      <td>Life Insurance</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Symbol  ...                                    Industry\n",
              "0   AACG  ...              Service to the Health Industry\n",
              "1  AACIU  ...                                         NaN\n",
              "2   AADI  ...  Biotechnology: Pharmaceutical Preparations\n",
              "3    AAL  ...               Air Freight/Delivery Services\n",
              "4   AAME  ...                              Life Insurance\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5WqoS2FUWKq"
      },
      "source": [
        "tickers_ls = list(tickers[\"Symbol\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE_QHnUKUYB8",
        "outputId": "bcebfec3-bfdf-44fb-d8bf-d93ccd8d06ab"
      },
      "source": [
        "tickers_ls[:20] # list of all tickers, only showing top 20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AACG',\n",
              " 'AACIU',\n",
              " 'AADI',\n",
              " 'AAL',\n",
              " 'AAME',\n",
              " 'AAOI',\n",
              " 'AAON',\n",
              " 'AAPL',\n",
              " 'AATC',\n",
              " 'AAWW',\n",
              " 'ABCB',\n",
              " 'ABCL',\n",
              " 'ABCM',\n",
              " 'ABEO',\n",
              " 'ABGI',\n",
              " 'ABIO',\n",
              " 'ABMD',\n",
              " 'ABNB',\n",
              " 'ABOS',\n",
              " 'ABSI']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "BKTbxvKTUZYo",
        "outputId": "40a5911d-1dff-4e04-8d79-5cf880251bad"
      },
      "source": [
        "# choose a random company, plot it's data\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "comp = random.choice(tickers_ls)\n",
        "print(f\"company: {comp}\")\n",
        "\n",
        "# get data\n",
        "comp_tick = yf.Ticker(\"MSFT\")\n",
        "\n",
        "# get historical market data\n",
        "hist = comp_tick.history(period=\"max\")\n",
        "plt.plot(hist[\"Close\"])\n",
        "plt.title(f\"Closing price for {comp}\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "company: BANX\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b29aLIJUi1F"
      },
      "source": [
        "# utils code\n",
        "# assist\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "## Data Processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.externals import joblib \n",
        "\n",
        "\n",
        "#### DATA CREATION FUNCTIONS ####\n",
        "def create_data(file_list):\n",
        "    \"\"\"\n",
        "    Utility function to create a dataset from a filelist.\n",
        "    \"\"\"\n",
        "    counter = 1\n",
        "    df_list = pd.DataFrame()\n",
        "    for file in file_list:\n",
        "        if (os.stat(file).st_size != 0):\n",
        "            df = pd.read_csv(file, sep = \",\")\n",
        "            df['symbol'] = file\n",
        "            df_list = df_list.append(df)\n",
        "            print (counter, \" out of \", len(file_list))\n",
        "            counter += 1\n",
        "    return pd.DataFrame(df_list)\n",
        "\n",
        "\n",
        "def fetch_data():\n",
        "    \"\"\"\n",
        "    Get the files from the data folder. \n",
        "    \"\"\"\n",
        "    main_dir = os.getcwd()\n",
        "    # STOCKS\n",
        "    os.chdir(main_dir)\n",
        "    os.chdir(\"./data/Stocks\")\n",
        "    stock_list = os.listdir()\n",
        "    stocks = create_data(stock_list)\n",
        "    #ETFs\n",
        "    os.chdir(main_dir)\n",
        "    os.chdir(\"./data/ETFs\")\n",
        "    etf_list = os.listdir()\n",
        "    etf = create_data(etf_list)\n",
        "\n",
        "    return stocks, etf\n",
        "\n",
        "\n",
        "#### DATA PROCESSING FUNCTIONS ####\n",
        "def scale_df(data, model_name):\n",
        "    \"\"\"\n",
        "    This class takes in a pandas dataframe and generates \n",
        "    the normalized version of it\n",
        "    \"\"\"\n",
        "    # scales the data\n",
        "    scaler = MinMaxScaler()\n",
        "    df = scaler.fit_transform(data)\n",
        "    \n",
        "    return df, scaler\n",
        "\n",
        "\n",
        "def generate_ta(data):\n",
        "    \"\"\"\n",
        "    Runs ta on a dataset and saves to csv.\n",
        "    \"\"\"\n",
        "    # converts data into ta dataframe\n",
        "    df = add_all_ta_features(data, \"Open\", \"High\", \"Low\", \"Close\", \"Volume\", fillna=True)\n",
        "    df.to_csv(\"../data/df_ta.csv\")\n",
        "    \n",
        "\n",
        "def build_window(df, look_back, n_features):\n",
        "    \"\"\"\n",
        "    Builds sliding windows to shift the batch by 1 step at a time\n",
        "    \"\"\"\n",
        "    x_train = [] # This list contain the sequences to predict when training\n",
        "    y_train = [] # This list contain the next value of the sequences when training\n",
        "\n",
        "    for i in range(look_back, df.shape[0]):\n",
        "        x_train.append(df[i-look_back:i,0:n_features].tolist()) # ,0 used in order to return the values only\n",
        "        y_train.append(df[i,0].tolist()) # tolist() converts np array to simple array\n",
        "   \n",
        "    # Converting arrays from lists to np arrays. \n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "\n",
        "    # Rounding numbers to speed up training.\n",
        "    x_train = np.round(x_train, 5)\n",
        "    y_train = np.round(y_train, 5)\n",
        "\n",
        "    return x_train, y_train\n",
        "\n",
        "\n",
        "def trim_dataset(mat, batch_size):\n",
        "    \"\"\"\n",
        "    trims dataset to a size that's divisible by the batch size\n",
        "    \"\"\"\n",
        "\n",
        "    no_of_rows_drop = mat.shape[0] % batch_size\n",
        "    if(no_of_rows_drop > 0):\n",
        "        return mat[:-no_of_rows_drop]\n",
        "    else:\n",
        "        return mat\n",
        "\n",
        "#### FINAL PIPELINE FUNCTION ####\n",
        "def preproc_pipeline(data, name):\n",
        "    \"\"\"\n",
        "    The preprocessing pipeline takes in a csv of processed data and creates\n",
        "    the training, validation, and test sets\n",
        "    \"\"\"\n",
        "    # Scale values\n",
        "    data, scaler = scale_df(data, name)\n",
        "    # Split\n",
        "    train_set, testval_set = train_test_split(data, train_size=0.6, test_size=0.4, shuffle=False)\n",
        "    validation_set, test_set = train_test_split(testval_set, train_size=0.7, test_size=0.3, shuffle=False)\n",
        "    \n",
        "    return train_set, validation_set, test_set, scaler\n",
        "\n",
        "\n",
        "def model_preproc_pipeline(data, look_back, batch_size, n_features):\n",
        "    \"\"\"\n",
        "    preprocesses data for LSTM input\n",
        "    \"\"\"\n",
        "    x_train, y_train = build_window(data, look_back, n_features)\n",
        "\n",
        "    x_train = trim_dataset(x_train, batch_size)\n",
        "    y_train = trim_dataset(y_train, batch_size)\n",
        "\n",
        "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], n_features))\n",
        "    return x_train, y_train\n",
        "    \n",
        "\n",
        "def generate_dataset():\n",
        "        stocks, etf = create_data(\".\")\n",
        "        data = pd.concat([stocks, etf])\n",
        "        generate_ta(data)\n",
        "        # we have to read file\n",
        "        data = pd.read_csv(\"./df_ta.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVQr1E2TUmA_"
      },
      "source": [
        "from tensorflow import keras as keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "def baseline_lstm_model(n_features, batch_size, look_back):\n",
        "    \"\"\"\n",
        "    Returns a keras LSTM model. Our architecture will be kept \n",
        "    in this method.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(LSTM(units = 64, return_sequences = True, input_shape = (look_back, n_features)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(units = 128, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(units = 256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(units = 512, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(units = 256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(units = 128, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(units = 64))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(units = 1))\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, x_train, y_train, epochs, batch_size, lr):\n",
        "    \"\"\"\n",
        "    Takes a training dataset and a model and returns a trained model \n",
        "    after ts timesteps.\n",
        "    \"\"\"\n",
        "    model.fit(x_train, y_train, epochs = epochs, batch_size = batch_size)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc9htTKXUwqu"
      },
      "source": [
        "# Defining hyper parameters\n",
        "TIME_STEPS = 30\n",
        "BATCH_SIZE = 128\n",
        "N_FEATURES = 1\n",
        "lr = 0.0001 # learning rate\n",
        "EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnDiJQiyUpDg"
      },
      "source": [
        "regressor = baseline_lstm_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toirv99EUtun",
        "outputId": "39307b9a-20b4-47c0-9815-258ddf6230a8"
      },
      "source": [
        "regressor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_119 (LSTM)              (None, 30, 64)            16896     \n",
            "_________________________________________________________________\n",
            "dropout_119 (Dropout)        (None, 30, 64)            0         \n",
            "_________________________________________________________________\n",
            "lstm_120 (LSTM)              (None, 30, 128)           98816     \n",
            "_________________________________________________________________\n",
            "dropout_120 (Dropout)        (None, 30, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_121 (LSTM)              (None, 30, 256)           394240    \n",
            "_________________________________________________________________\n",
            "dropout_121 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_122 (LSTM)              (None, 30, 512)           1574912   \n",
            "_________________________________________________________________\n",
            "dropout_122 (Dropout)        (None, 30, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_123 (LSTM)              (None, 30, 256)           787456    \n",
            "_________________________________________________________________\n",
            "dropout_123 (Dropout)        (None, 30, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_124 (LSTM)              (None, 30, 128)           197120    \n",
            "_________________________________________________________________\n",
            "dropout_124 (Dropout)        (None, 30, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_125 (LSTM)              (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dropout_125 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,118,913\n",
            "Trainable params: 3,118,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxNjQzzfU0Pq"
      },
      "source": [
        "# Prediction model 1 based on George V Jose\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def predict(data, num_prediction):\n",
        "    # Scaling data\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(data)\n",
        "\n",
        "    # Looking at last TIME_STEPS value\n",
        "    prediction_list = scaled[-TIME_STEPS:]\n",
        "    \n",
        "    for _ in range(num_prediction):\n",
        "        # Looking at last TIME_STEPS value (1 of our batch)\n",
        "        x = prediction_list[-TIME_STEPS:]\n",
        "        x = np.array(x)\n",
        "        \n",
        "        # 1 batch with TIME_STEPS and 1 feature\n",
        "        x = x.reshape((1, TIME_STEPS, 1))\n",
        "        \n",
        "        # prediction\n",
        "        print(\"predicting batch \", x)\n",
        "        output = model.predict(x)[0][0]\n",
        "        \n",
        "        # Appends prediction results back into \n",
        "        prediction_list = np.append(prediction_list, output)\n",
        "        \n",
        "    prediction_list = prediction_list[TIME_STEPS - 1:]\n",
        "    \n",
        "    # Reverse the scaling\n",
        "    prediction_list = prediction_list.reshape(num_prediction+1, 1)\n",
        "    prediction_list = scaler.inverse_transform(prediction_list)\n",
        "    \n",
        "    return prediction_list\n",
        "\n",
        "# Prediction model 2 based on Ravindra Compella\n",
        "def moving_test_window_preds(data, num_predictions, TIME_STEPS, model):\n",
        "    prediction_list = []\n",
        "    \n",
        "    # Scaling data\n",
        "    scaler = MinMaxScaler()\n",
        "    data = scaler.fit_transform(data)\n",
        "    \n",
        "    moving_test_window = data[-TIME_STEPS:]\n",
        "    moving_test_window = np.array(moving_test_window)\n",
        "    \n",
        "    # Scaling data\n",
        "    # scaler = MinMaxScaler()\n",
        "    # moving_test_window = scaler.fit_transform(moving_test_window)\n",
        "    \n",
        "    # Reshaping data\n",
        "    moving_test_window = moving_test_window.reshape((1, TIME_STEPS, 1))\n",
        "    \n",
        "    for i in range(num_predictions):\n",
        "        # print(\"predicting batch \", moving_test_window)\n",
        "        preds_one_step = model.predict(moving_test_window)\n",
        "        prediction_list.append(preds_one_step[0,0])\n",
        "        preds_one_step = preds_one_step.reshape(1,1,1)\n",
        "        moving_test_window = np.concatenate((moving_test_window[:,1:,:], preds_one_step), axis=1)\n",
        "        \n",
        "    prediction_list = np.array(prediction_list)\n",
        "    prediction_list = prediction_list.reshape(num_predictions, 1)\n",
        "    prediction_list = scaler.inverse_transform(prediction_list)\n",
        "    \n",
        "    return prediction_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTR86k12U7oh"
      },
      "source": [
        "top_companies = ['AMZN', 'AAPL', 'NFLX', 'GOOG', 'MSFT', 'GOOGL', 'TSLA', 'CSCO', 'COST', 'FB']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHaigtvPeCRJ",
        "outputId": "077760d9-8b59-4267-8bf7-089a853b0789"
      },
      "source": [
        "for i in range(len(top_companies)):\n",
        "    comp = top_companies[i]\n",
        "    comp_tick = yf.Ticker(comp)\n",
        "    # get historical market data\n",
        "    hist = comp_tick.history(period=\"max\")\n",
        "    print(f\"{comp}: {len(hist) * 0.4 * 0.3 // 2}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AMZN: 369.0\n",
            "AAPL: 618.0\n",
            "NFLX: 294.0\n",
            "GOOG: 260.0\n",
            "MSFT: 539.0\n",
            "GOOGL: 260.0\n",
            "TSLA: 171.0\n",
            "CSCO: 479.0\n",
            "COST: 534.0\n",
            "FB: 143.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJvnO3jqU9N2",
        "outputId": "26d8cb8a-d9c0-4830-dc3c-a9c2803610ad"
      },
      "source": [
        "# Defining hyper parameters\n",
        "TIME_STEPS = 100\n",
        "BATCH_SIZE = 128\n",
        "N_FEATURES = 1\n",
        "lr = 0.0001 # learning rate\n",
        "EPOCHS = 5\n",
        "# result generation\n",
        "\n",
        "for i in range(len(top_companies)):\n",
        "    comp = top_companies[i]\n",
        "    comp_tick = yf.Ticker(comp)\n",
        "    # get historical market data\n",
        "    hist = comp_tick.history(period=\"max\")\n",
        "    # train data\n",
        "    # we only use closing price\n",
        "    data = hist.iloc[:,1:2]\n",
        "    train, valid, test, scalar = preproc_pipeline(data, False)\n",
        "    # Create windows, trim windows, and reshape for LSTM input\n",
        "    x_train, y_train = model_preproc_pipeline(train, TIME_STEPS, BATCH_SIZE, N_FEATURES)\n",
        "\n",
        "    regressor = baseline_lstm_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)\n",
        "\n",
        "    # train model\n",
        "    # Training the model\n",
        "    regressor = train_model(regressor, x_train, y_train, EPOCHS, BATCH_SIZE, lr)\n",
        "\n",
        "    # Preparing test and validation sets\n",
        "    df_test = trim_dataset(test, BATCH_SIZE)\n",
        "    df_val, df_testing = np.split(df_test, 2)\n",
        "\n",
        "    n_samples = len(df_testing)\n",
        "\n",
        "    unseen_predictions = moving_test_window_preds(df_val, n_samples, TIME_STEPS, regressor)\n",
        "\n",
        "    # Evaluating model for unseen data\n",
        "    mse = mean_squared_error(df_testing[:n_samples], unseen_predictions[:n_samples])\n",
        "    n_mse = mse / (df_testing[:n_samples]).mean()\n",
        "    print(f\"comp: {comp} mse: {mse} norm_mse: {n_mse}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "28/28 [==============================] - 17s 282ms/step - loss: 2.8646e-04\n",
            "Epoch 2/5\n",
            "28/28 [==============================] - 8s 279ms/step - loss: 1.3426e-04\n",
            "Epoch 3/5\n",
            "28/28 [==============================] - 8s 279ms/step - loss: 2.5507e-05\n",
            "Epoch 4/5\n",
            "28/28 [==============================] - 8s 278ms/step - loss: 1.2906e-05\n",
            "Epoch 5/5\n",
            "28/28 [==============================] - 8s 278ms/step - loss: 1.1206e-05\n",
            "comp: AMZN mse: 0.16148725352399126 norm_mse: 0.20177705508896324\n",
            "Epoch 1/5\n",
            "47/47 [==============================] - 23s 281ms/step - loss: 9.7539e-05\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 13s 279ms/step - loss: 2.6217e-06\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 13s 278ms/step - loss: 2.2641e-06\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 13s 278ms/step - loss: 2.0595e-06\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 13s 278ms/step - loss: 2.0334e-06\n",
            "comp: AAPL mse: 0.20415483832183037 norm_mse: 0.35877240162690377\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 16s 283ms/step - loss: 3.8305e-04\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 6s 279ms/step - loss: 5.8100e-05\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 6s 280ms/step - loss: 2.1213e-05\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 6s 280ms/step - loss: 1.9069e-05\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 6s 279ms/step - loss: 1.6035e-05\n",
            "comp: NFLX mse: 0.05509569968063793 norm_mse: 0.07321669407576314\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 14s 284ms/step - loss: 0.0054\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 5s 278ms/step - loss: 0.0012\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 5s 279ms/step - loss: 2.7338e-04\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 5s 280ms/step - loss: 1.4520e-04\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 5s 278ms/step - loss: 1.2501e-04\n",
            "comp: GOOG mse: 0.11418363645754574 norm_mse: 0.15045523717766165\n",
            "Epoch 1/5\n",
            "41/41 [==============================] - 21s 280ms/step - loss: 5.6813e-04\n",
            "Epoch 2/5\n",
            "41/41 [==============================] - 11s 278ms/step - loss: 3.9841e-05\n",
            "Epoch 3/5\n",
            "41/41 [==============================] - 11s 278ms/step - loss: 2.8674e-05\n",
            "Epoch 4/5\n",
            "41/41 [==============================] - 11s 278ms/step - loss: 2.8007e-05\n",
            "Epoch 5/5\n",
            "41/41 [==============================] - 11s 277ms/step - loss: 2.5556e-05\n",
            "comp: MSFT mse: 0.15046546230755947 norm_mse: 0.2526072305575891\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 14s 284ms/step - loss: 0.0023\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 5s 280ms/step - loss: 3.0865e-04\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 5s 279ms/step - loss: 1.5010e-04\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 5s 278ms/step - loss: 1.3055e-04\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 5s 278ms/step - loss: 1.2138e-04\n",
            "comp: GOOGL mse: 0.10938416982389554 norm_mse: 0.14549287298017496\n",
            "Epoch 1/5\n",
            "12/12 [==============================] - 13s 287ms/step - loss: 4.7621e-04\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 3s 280ms/step - loss: 2.1207e-04\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 3s 278ms/step - loss: 1.4456e-04\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 3s 280ms/step - loss: 6.6855e-05\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 3s 280ms/step - loss: 2.8071e-05\n",
            "comp: TSLA mse: 0.09384907953964111 norm_mse: 0.1631921151981751\n",
            "Epoch 1/5\n",
            "36/36 [==============================] - 20s 281ms/step - loss: 0.0421\n",
            "Epoch 2/5\n",
            "36/36 [==============================] - 10s 279ms/step - loss: 0.0024\n",
            "Epoch 3/5\n",
            "36/36 [==============================] - 10s 279ms/step - loss: 0.0016\n",
            "Epoch 4/5\n",
            "36/36 [==============================] - 10s 279ms/step - loss: 0.0017\n",
            "Epoch 5/5\n",
            "36/36 [==============================] - 10s 278ms/step - loss: 0.0016\n",
            "comp: CSCO mse: 0.010893279570005465 norm_mse: 0.014605211584141829\n",
            "Epoch 1/5\n",
            "40/40 [==============================] - 20s 281ms/step - loss: 2.8805e-04\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 2.1583e-05\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 1.8963e-05\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 11s 279ms/step - loss: 1.6977e-05\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 11s 278ms/step - loss: 2.0962e-05\n",
            "comp: COST mse: 0.09952712090981569 norm_mse: 0.15518589441049682\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 12s 286ms/step - loss: 0.1174\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 282ms/step - loss: 0.0168\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 278ms/step - loss: 0.0096\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 3s 278ms/step - loss: 0.0035\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 278ms/step - loss: 0.0016\n",
            "comp: FB mse: 0.03079915094938817 norm_mse: 0.034926947549180666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BojR73ldVDAT"
      },
      "source": [
        "from tensorflow.keras.layers import LSTM, GRU\n",
        "def baseline_gru_model(n_features, batch_size, look_back):\n",
        "    \"\"\"\n",
        "    Returns a keras LSTM model. Our architecture will be kept \n",
        "    in this method.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(GRU(units = 64, return_sequences = True, input_shape = (look_back, n_features)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(GRU(units = 128, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(GRU(units = 256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(GRU(units = 512, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(GRU(units = 256, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(GRU(units = 128, return_sequences = True))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(GRU(units = 64))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(units = 1))\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEaBbj2qlIfR"
      },
      "source": [
        "regressor = baseline_gru_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ6nQZYrlMYy",
        "outputId": "c8b3fbdf-f1ed-48d3-9561-3cea2393e6cb"
      },
      "source": [
        "regressor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 100, 64)           12864     \n",
            "_________________________________________________________________\n",
            "dropout_280 (Dropout)        (None, 100, 64)           0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100, 128)          74496     \n",
            "_________________________________________________________________\n",
            "dropout_281 (Dropout)        (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 100, 256)          296448    \n",
            "_________________________________________________________________\n",
            "dropout_282 (Dropout)        (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 100, 512)          1182720   \n",
            "_________________________________________________________________\n",
            "dropout_283 (Dropout)        (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 100, 256)          591360    \n",
            "_________________________________________________________________\n",
            "dropout_284 (Dropout)        (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (None, 100, 128)          148224    \n",
            "_________________________________________________________________\n",
            "dropout_285 (Dropout)        (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (None, 64)                37248     \n",
            "_________________________________________________________________\n",
            "dropout_286 (Dropout)        (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 2,343,425\n",
            "Trainable params: 2,343,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFp4wXBAlNk7",
        "outputId": "54faeb19-db7f-4515-a81e-2e1cc3213aee"
      },
      "source": [
        "# Defining hyper parameters\n",
        "TIME_STEPS = 100\n",
        "BATCH_SIZE = 128\n",
        "N_FEATURES = 1\n",
        "lr = 0.0001 # learning rate\n",
        "EPOCHS = 5\n",
        "# result generation\n",
        "\n",
        "for i in range(len(top_companies)):\n",
        "    comp = top_companies[i]\n",
        "    comp_tick = yf.Ticker(comp)\n",
        "    # get historical market data\n",
        "    hist = comp_tick.history(period=\"max\")\n",
        "    # train data\n",
        "    # we only use closing price\n",
        "    data = hist.iloc[:,1:2]\n",
        "    train, valid, test, scalar = preproc_pipeline(data, False)\n",
        "    # Create windows, trim windows, and reshape for LSTM input\n",
        "    x_train, y_train = model_preproc_pipeline(train, TIME_STEPS, BATCH_SIZE, N_FEATURES)\n",
        "\n",
        "    regressor = baseline_gru_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)\n",
        "\n",
        "    # train model\n",
        "    # Training the model\n",
        "    regressor = train_model(regressor, x_train, y_train, EPOCHS, BATCH_SIZE, lr)\n",
        "\n",
        "    # Preparing test and validation sets\n",
        "    df_test = trim_dataset(test, BATCH_SIZE)\n",
        "    df_val, df_testing = np.split(df_test, 2)\n",
        "\n",
        "    n_samples = len(df_testing)\n",
        "\n",
        "    unseen_predictions = moving_test_window_preds(df_val, n_samples, TIME_STEPS, regressor)\n",
        "\n",
        "    # Evaluating model for unseen data\n",
        "    mse = mean_squared_error(df_testing[:n_samples], unseen_predictions[:n_samples])\n",
        "    n_mse = mse / (df_testing[:n_samples]).mean()\n",
        "    print(f\"comp: {comp} mse: {mse} norm_mse: {n_mse}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "28/28 [==============================] - 16s 257ms/step - loss: 8.6987e-04\n",
            "Epoch 2/5\n",
            "28/28 [==============================] - 7s 253ms/step - loss: 1.5475e-04\n",
            "Epoch 3/5\n",
            "28/28 [==============================] - 7s 254ms/step - loss: 2.7175e-05\n",
            "Epoch 4/5\n",
            "28/28 [==============================] - 7s 254ms/step - loss: 1.1781e-05\n",
            "Epoch 5/5\n",
            "28/28 [==============================] - 7s 253ms/step - loss: 9.9142e-06\n",
            "comp: AMZN mse: 0.13675016089688813 norm_mse: 0.17086825211636059\n",
            "Epoch 1/5\n",
            "47/47 [==============================] - 21s 254ms/step - loss: 3.4384e-04\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 12s 254ms/step - loss: 5.3098e-06\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 12s 252ms/step - loss: 3.7586e-06\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 12s 253ms/step - loss: 3.2913e-06\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 12s 252ms/step - loss: 3.0278e-06\n",
            "comp: AAPL mse: 0.20410848672142076 norm_mse: 0.3586909446121504\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 15s 257ms/step - loss: 9.6242e-04\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 6s 253ms/step - loss: 1.1506e-04\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 6s 256ms/step - loss: 2.4816e-05\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 6s 254ms/step - loss: 1.4451e-05\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 6s 252ms/step - loss: 1.2743e-05\n",
            "comp: NFLX mse: 0.0397982134550155 norm_mse: 0.05288785941894134\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 14s 260ms/step - loss: 0.0018\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 5s 254ms/step - loss: 2.4517e-04\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 5s 252ms/step - loss: 9.9927e-05\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 7.8457e-05\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 5s 254ms/step - loss: 6.9436e-05\n",
            "comp: GOOG mse: 0.13915243950415604 norm_mse: 0.18335563605238864\n",
            "Epoch 1/5\n",
            "41/41 [==============================] - 20s 257ms/step - loss: 6.2847e-04\n",
            "Epoch 2/5\n",
            "41/41 [==============================] - 10s 253ms/step - loss: 3.0498e-05\n",
            "Epoch 3/5\n",
            "41/41 [==============================] - 10s 255ms/step - loss: 2.3082e-05\n",
            "Epoch 4/5\n",
            "41/41 [==============================] - 10s 253ms/step - loss: 2.0426e-05\n",
            "Epoch 5/5\n",
            "41/41 [==============================] - 10s 253ms/step - loss: 2.4241e-05\n",
            "comp: MSFT mse: 0.09568581109306279 norm_mse: 0.1606410364067448\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 14s 260ms/step - loss: 0.0028\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 3.3206e-04\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 1.2053e-04\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 8.1114e-05\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 5s 253ms/step - loss: 8.5987e-05\n",
            "comp: GOOGL mse: 0.1244019890357001 norm_mse: 0.16546821005628076\n",
            "Epoch 1/5\n",
            "12/12 [==============================] - 12s 267ms/step - loss: 0.0012\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 3s 254ms/step - loss: 2.5000e-04\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 3s 255ms/step - loss: 1.8169e-04\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 3s 256ms/step - loss: 5.4661e-05\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 3s 253ms/step - loss: 2.7054e-05\n",
            "comp: TSLA mse: 0.009121011543696794 norm_mse: 0.015860327814234246\n",
            "Epoch 1/5\n",
            "36/36 [==============================] - 19s 257ms/step - loss: 0.0184\n",
            "Epoch 2/5\n",
            "36/36 [==============================] - 9s 253ms/step - loss: 0.0014\n",
            "Epoch 3/5\n",
            "36/36 [==============================] - 9s 253ms/step - loss: 0.0010\n",
            "Epoch 4/5\n",
            "36/36 [==============================] - 9s 252ms/step - loss: 9.8326e-04\n",
            "Epoch 5/5\n",
            "36/36 [==============================] - 9s 252ms/step - loss: 0.0012\n",
            "comp: CSCO mse: 0.017998626112851326 norm_mse: 0.024131735595305917\n",
            "Epoch 1/5\n",
            "40/40 [==============================] - 19s 257ms/step - loss: 7.8813e-04\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 10s 255ms/step - loss: 2.3997e-05\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 10s 253ms/step - loss: 1.7674e-05\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 10s 252ms/step - loss: 1.8991e-05\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 10s 252ms/step - loss: 1.5424e-05\n",
            "comp: COST mse: 0.10776272799191368 norm_mse: 0.1680271178203471\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 11s 257ms/step - loss: 0.0131\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 3s 252ms/step - loss: 0.0024\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 3s 252ms/step - loss: 0.0012\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 2s 248ms/step - loss: 7.3347e-04\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 3s 253ms/step - loss: 5.3660e-04\n",
            "comp: FB mse: 0.028250250136275183 norm_mse: 0.03203643523752781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnKVeMK2lYOP"
      },
      "source": [
        "from tensorflow.keras.layers import LSTM, GRU, Bidirectional\n",
        "def baseline_gru_model(n_features, batch_size, look_back):\n",
        "    \"\"\"\n",
        "    Returns a keras LSTM model. Our architecture will be kept \n",
        "    in this method.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Bidirectional(GRU(units = 64, return_sequences = True, input_shape = (look_back, n_features))))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(GRU(units = 128, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(GRU(units = 256, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(GRU(units = 512, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(GRU(units = 256, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(GRU(units = 128, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(GRU(units = 64)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(units = 1))\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MkxRsJ-qHEx"
      },
      "source": [
        "regressor = baseline_gru_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)\n",
        "regressor.build((None, TIME_STEPS, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d05fPlyGqJyj",
        "outputId": "dfc562b1-5cce-4d52-9bb0-e20e3a2b1af8"
      },
      "source": [
        "regressor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_21 (Bidirectio (None, 100, 128)          25728     \n",
            "_________________________________________________________________\n",
            "dropout_378 (Dropout)        (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_22 (Bidirectio (None, 100, 256)          198144    \n",
            "_________________________________________________________________\n",
            "dropout_379 (Dropout)        (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_23 (Bidirectio (None, 100, 512)          789504    \n",
            "_________________________________________________________________\n",
            "dropout_380 (Dropout)        (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_24 (Bidirectio (None, 100, 1024)         3151872   \n",
            "_________________________________________________________________\n",
            "dropout_381 (Dropout)        (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_25 (Bidirectio (None, 100, 512)          1969152   \n",
            "_________________________________________________________________\n",
            "dropout_382 (Dropout)        (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_26 (Bidirectio (None, 100, 256)          493056    \n",
            "_________________________________________________________________\n",
            "dropout_383 (Dropout)        (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_27 (Bidirectio (None, 128)               123648    \n",
            "_________________________________________________________________\n",
            "dropout_384 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 6,751,233\n",
            "Trainable params: 6,751,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUaQwZZiqLUB",
        "outputId": "fa0508e9-551a-4998-dcd3-66148bacb48d"
      },
      "source": [
        "# Defining hyper parameters\n",
        "TIME_STEPS = 100\n",
        "BATCH_SIZE = 128\n",
        "N_FEATURES = 1\n",
        "lr = 0.0001 # learning rate\n",
        "EPOCHS = 5\n",
        "# result generation\n",
        "\n",
        "for i in range(len(top_companies)):\n",
        "    comp = top_companies[i]\n",
        "    comp_tick = yf.Ticker(comp)\n",
        "    # get historical market data\n",
        "    hist = comp_tick.history(period=\"max\")\n",
        "    # train data\n",
        "    # we only use closing price\n",
        "    data = hist.iloc[:,1:2]\n",
        "    train, valid, test, scalar = preproc_pipeline(data, False)\n",
        "    # Create windows, trim windows, and reshape for LSTM input\n",
        "    x_train, y_train = model_preproc_pipeline(train, TIME_STEPS, BATCH_SIZE, N_FEATURES)\n",
        "\n",
        "    regressor = baseline_gru_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)\n",
        "\n",
        "    # train model\n",
        "    # Training the model\n",
        "    regressor = train_model(regressor, x_train, y_train, EPOCHS, BATCH_SIZE, lr)\n",
        "\n",
        "    # Preparing test and validation sets\n",
        "    df_test = trim_dataset(test, BATCH_SIZE)\n",
        "    df_val, df_testing = np.split(df_test, 2)\n",
        "\n",
        "    n_samples = len(df_testing)\n",
        "\n",
        "    unseen_predictions = moving_test_window_preds(df_val, n_samples, TIME_STEPS, regressor)\n",
        "\n",
        "    # Evaluating model for unseen data\n",
        "    mse = mean_squared_error(df_testing[:n_samples], unseen_predictions[:n_samples])\n",
        "    n_mse = mse / (df_testing[:n_samples]).mean()\n",
        "    print(f\"comp: {comp} mse: {mse} norm_mse: {n_mse}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "28/28 [==============================] - 38s 601ms/step - loss: 0.0013\n",
            "Epoch 2/5\n",
            "28/28 [==============================] - 17s 600ms/step - loss: 3.6660e-05\n",
            "Epoch 3/5\n",
            "28/28 [==============================] - 17s 599ms/step - loss: 1.5451e-05\n",
            "Epoch 4/5\n",
            "28/28 [==============================] - 17s 598ms/step - loss: 1.2834e-05\n",
            "Epoch 5/5\n",
            "28/28 [==============================] - 17s 598ms/step - loss: 1.0963e-05\n",
            "comp: AMZN mse: 0.12736568855118652 norm_mse: 0.15914242761840314\n",
            "Epoch 1/5\n",
            "47/47 [==============================] - 50s 602ms/step - loss: 8.4289e-04\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 28s 598ms/step - loss: 1.0919e-05\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 28s 598ms/step - loss: 8.6556e-06\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 28s 597ms/step - loss: 7.1475e-06\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 28s 597ms/step - loss: 6.0337e-06\n",
            "comp: AAPL mse: 0.20389956142873555 norm_mse: 0.35832378936413484\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 35s 598ms/step - loss: 0.0023\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 13s 598ms/step - loss: 1.0350e-04\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 13s 599ms/step - loss: 2.5366e-05\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 13s 599ms/step - loss: 1.5688e-05\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 13s 599ms/step - loss: 1.4871e-05\n",
            "comp: NFLX mse: 0.06288570869790515 norm_mse: 0.08356883971273249\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 33s 598ms/step - loss: 0.0093\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 11s 601ms/step - loss: 3.3755e-04\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 11s 599ms/step - loss: 1.1311e-04\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 11s 600ms/step - loss: 7.1555e-05\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 11s 600ms/step - loss: 6.9493e-05\n",
            "comp: GOOG mse: 0.12388145556366768 norm_mse: 0.16323366777406445\n",
            "Epoch 1/5\n",
            "41/41 [==============================] - 47s 600ms/step - loss: 0.0017\n",
            "Epoch 2/5\n",
            "41/41 [==============================] - 25s 597ms/step - loss: 2.9458e-05\n",
            "Epoch 3/5\n",
            "41/41 [==============================] - 24s 597ms/step - loss: 2.2526e-05\n",
            "Epoch 4/5\n",
            "41/41 [==============================] - 25s 598ms/step - loss: 2.2170e-05\n",
            "Epoch 5/5\n",
            "41/41 [==============================] - 25s 598ms/step - loss: 1.9989e-05\n",
            "comp: MSFT mse: 0.10594987163828162 norm_mse: 0.17787273782991525\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 33s 602ms/step - loss: 0.0058\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 11s 601ms/step - loss: 2.8401e-04\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 11s 598ms/step - loss: 1.2564e-04\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 11s 598ms/step - loss: 7.6758e-05\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 11s 595ms/step - loss: 7.1452e-05\n",
            "comp: GOOGL mse: 0.09139956580263049 norm_mse: 0.12157138861294578\n",
            "Epoch 1/5\n",
            "12/12 [==============================] - 29s 595ms/step - loss: 0.0046\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 7s 596ms/step - loss: 2.8387e-04\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 8.2728e-05\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 7s 594ms/step - loss: 3.6847e-05\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 7s 595ms/step - loss: 2.4872e-05\n",
            "comp: TSLA mse: 0.05256311864582051 norm_mse: 0.09140085928707327\n",
            "Epoch 1/5\n",
            "36/36 [==============================] - 43s 603ms/step - loss: 0.0148\n",
            "Epoch 2/5\n",
            "36/36 [==============================] - 22s 600ms/step - loss: 0.0011\n",
            "Epoch 3/5\n",
            "36/36 [==============================] - 22s 600ms/step - loss: 8.7600e-04\n",
            "Epoch 4/5\n",
            "36/36 [==============================] - 22s 603ms/step - loss: 8.9339e-04\n",
            "Epoch 5/5\n",
            "36/36 [==============================] - 22s 599ms/step - loss: 7.6552e-04\n",
            "comp: CSCO mse: 0.02324582715968627 norm_mse: 0.031166939108173846\n",
            "Epoch 1/5\n",
            "40/40 [==============================] - 46s 602ms/step - loss: 0.0015\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 24s 600ms/step - loss: 2.4957e-05\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 24s 599ms/step - loss: 1.6329e-05\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 24s 600ms/step - loss: 1.5775e-05\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 24s 599ms/step - loss: 1.6265e-05\n",
            "comp: COST mse: 0.07346740703852112 norm_mse: 0.11455274875820654\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 28s 602ms/step - loss: 0.0377\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 6s 604ms/step - loss: 0.0025\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 6s 600ms/step - loss: 9.0581e-04\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 6s 605ms/step - loss: 5.9549e-04\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 6s 601ms/step - loss: 4.7267e-04\n",
            "comp: FB mse: 0.03170501653555129 norm_mse: 0.03595422001738992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYHiFAikrCZs"
      },
      "source": [
        "def baseline_bilstm_model(n_features, batch_size, look_back):\n",
        "    \"\"\"\n",
        "    Returns a keras LSTM model. Our architecture will be kept \n",
        "    in this method.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units = 64, return_sequences = True, input_shape = (look_back, n_features))))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units = 128, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units = 256, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units = 512, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units = 256, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units = 128, return_sequences = True)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(units = 64)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(units = 1))\n",
        "\n",
        "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHRaWvtBzKkE"
      },
      "source": [
        "regressor = baseline_bilstm_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)\n",
        "regressor.build((None, TIME_STEPS, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f381KQhHzQgu",
        "outputId": "52329b3e-c29a-4209-ffcf-46833889a38c"
      },
      "source": [
        "regressor.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_98 (Bidirectio (None, 100, 128)          33792     \n",
            "_________________________________________________________________\n",
            "dropout_455 (Dropout)        (None, 100, 128)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_99 (Bidirectio (None, 100, 256)          263168    \n",
            "_________________________________________________________________\n",
            "dropout_456 (Dropout)        (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_100 (Bidirecti (None, 100, 512)          1050624   \n",
            "_________________________________________________________________\n",
            "dropout_457 (Dropout)        (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_101 (Bidirecti (None, 100, 1024)         4198400   \n",
            "_________________________________________________________________\n",
            "dropout_458 (Dropout)        (None, 100, 1024)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_102 (Bidirecti (None, 100, 512)          2623488   \n",
            "_________________________________________________________________\n",
            "dropout_459 (Dropout)        (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_103 (Bidirecti (None, 100, 256)          656384    \n",
            "_________________________________________________________________\n",
            "dropout_460 (Dropout)        (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_104 (Bidirecti (None, 128)               164352    \n",
            "_________________________________________________________________\n",
            "dropout_461 (Dropout)        (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_65 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 8,990,337\n",
            "Trainable params: 8,990,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGbV_FQQzSTK",
        "outputId": "34df31f7-0dac-47c4-b531-ed103b69e64a"
      },
      "source": [
        "# Defining hyper parameters\n",
        "TIME_STEPS = 100\n",
        "BATCH_SIZE = 128\n",
        "N_FEATURES = 1\n",
        "lr = 0.0001 # learning rate\n",
        "EPOCHS = 5\n",
        "# result generation\n",
        "\n",
        "for i in range(len(top_companies)):\n",
        "    comp = top_companies[i]\n",
        "    comp_tick = yf.Ticker(comp)\n",
        "    # get historical market data\n",
        "    hist = comp_tick.history(period=\"max\")\n",
        "    # train data\n",
        "    # we only use closing price\n",
        "    data = hist.iloc[:,1:2]\n",
        "    train, valid, test, scalar = preproc_pipeline(data, False)\n",
        "    # Create windows, trim windows, and reshape for LSTM input\n",
        "    x_train, y_train = model_preproc_pipeline(train, TIME_STEPS, BATCH_SIZE, N_FEATURES)\n",
        "\n",
        "    regressor = baseline_bilstm_model(N_FEATURES, BATCH_SIZE, TIME_STEPS)\n",
        "\n",
        "    # train model\n",
        "    # Training the model\n",
        "    regressor = train_model(regressor, x_train, y_train, EPOCHS, BATCH_SIZE, lr)\n",
        "\n",
        "    # Preparing test and validation sets\n",
        "    df_test = trim_dataset(test, BATCH_SIZE)\n",
        "    df_val, df_testing = np.split(df_test, 2)\n",
        "\n",
        "    n_samples = len(df_testing)\n",
        "\n",
        "    unseen_predictions = moving_test_window_preds(df_val, n_samples, TIME_STEPS, regressor)\n",
        "\n",
        "    # Evaluating model for unseen data\n",
        "    mse = mean_squared_error(df_testing[:n_samples], unseen_predictions[:n_samples])\n",
        "    n_mse = mse / (df_testing[:n_samples]).mean()\n",
        "    print(f\"comp: {comp} mse: {mse} norm_mse: {n_mse}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "28/28 [==============================] - 42s 675ms/step - loss: 5.8746e-04\n",
            "Epoch 2/5\n",
            "28/28 [==============================] - 19s 676ms/step - loss: 1.4806e-05\n",
            "Epoch 3/5\n",
            "28/28 [==============================] - 19s 675ms/step - loss: 1.2725e-05\n",
            "Epoch 4/5\n",
            "28/28 [==============================] - 19s 671ms/step - loss: 9.7073e-06\n",
            "Epoch 5/5\n",
            "28/28 [==============================] - 19s 669ms/step - loss: 1.1535e-05\n",
            "comp: AMZN mse: 0.1627238702816046 norm_mse: 0.203322198016221\n",
            "Epoch 1/5\n",
            "47/47 [==============================] - 56s 675ms/step - loss: 2.5877e-04\n",
            "Epoch 2/5\n",
            "47/47 [==============================] - 32s 674ms/step - loss: 3.0880e-06\n",
            "Epoch 3/5\n",
            "47/47 [==============================] - 32s 671ms/step - loss: 2.6930e-06\n",
            "Epoch 4/5\n",
            "47/47 [==============================] - 32s 673ms/step - loss: 2.4056e-06\n",
            "Epoch 5/5\n",
            "47/47 [==============================] - 32s 672ms/step - loss: 2.2128e-06\n",
            "comp: AAPL mse: 0.2036473019033499 norm_mse: 0.35788047926606104\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 39s 675ms/step - loss: 7.0993e-04\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 15s 674ms/step - loss: 2.4164e-05\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 15s 673ms/step - loss: 1.3976e-05\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 15s 670ms/step - loss: 1.1601e-05\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 15s 671ms/step - loss: 1.0714e-05\n",
            "comp: NFLX mse: 0.06459407159621967 norm_mse: 0.08583908375031271\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 37s 676ms/step - loss: 0.0039\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 13s 676ms/step - loss: 1.8776e-04\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 13s 671ms/step - loss: 9.1702e-05\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 13s 671ms/step - loss: 7.2628e-05\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 13s 670ms/step - loss: 7.1218e-05\n",
            "comp: GOOG mse: 0.13304064268317178 norm_mse: 0.17530236442073274\n",
            "Epoch 1/5\n",
            "41/41 [==============================] - 52s 675ms/step - loss: 5.8189e-04\n",
            "Epoch 2/5\n",
            "41/41 [==============================] - 28s 673ms/step - loss: 2.6818e-05\n",
            "Epoch 3/5\n",
            "41/41 [==============================] - 27s 670ms/step - loss: 1.9531e-05\n",
            "Epoch 4/5\n",
            "41/41 [==============================] - 27s 670ms/step - loss: 1.9562e-05\n",
            "Epoch 5/5\n",
            "41/41 [==============================] - 27s 670ms/step - loss: 1.8776e-05\n",
            "comp: MSFT mse: 0.14096144315893822 norm_mse: 0.23665151629195333\n",
            "Epoch 1/5\n",
            "19/19 [==============================] - 36s 675ms/step - loss: 0.0027\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 13s 675ms/step - loss: 2.0057e-04\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 13s 673ms/step - loss: 9.9430e-05\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 13s 676ms/step - loss: 8.0679e-05\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 13s 673ms/step - loss: 7.3973e-05\n",
            "comp: GOOGL mse: 0.10992632260459292 norm_mse: 0.14621399529417017\n",
            "Epoch 1/5\n",
            "12/12 [==============================] - 32s 677ms/step - loss: 7.5981e-04\n",
            "Epoch 2/5\n",
            "12/12 [==============================] - 8s 674ms/step - loss: 1.2363e-04\n",
            "Epoch 3/5\n",
            "12/12 [==============================] - 8s 676ms/step - loss: 3.3051e-05\n",
            "Epoch 4/5\n",
            "12/12 [==============================] - 8s 676ms/step - loss: 1.8210e-05\n",
            "Epoch 5/5\n",
            "12/12 [==============================] - 8s 672ms/step - loss: 1.4214e-05\n",
            "comp: TSLA mse: 0.05085607835986375 norm_mse: 0.08843252420738704\n",
            "Epoch 1/5\n",
            "36/36 [==============================] - 48s 675ms/step - loss: 0.0137\n",
            "Epoch 2/5\n",
            "36/36 [==============================] - 24s 673ms/step - loss: 0.0017\n",
            "Epoch 3/5\n",
            "36/36 [==============================] - 24s 672ms/step - loss: 0.0010\n",
            "Epoch 4/5\n",
            "36/36 [==============================] - 24s 670ms/step - loss: 9.7565e-04\n",
            "Epoch 5/5\n",
            "36/36 [==============================] - 24s 668ms/step - loss: 0.0010\n",
            "comp: CSCO mse: 0.017843065096772685 norm_mse: 0.023923164958169957\n",
            "Epoch 1/5\n",
            "40/40 [==============================] - 50s 668ms/step - loss: 3.3656e-04\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 27s 669ms/step - loss: 1.9589e-05\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 27s 668ms/step - loss: 1.3497e-05\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 27s 669ms/step - loss: 1.4394e-05\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 27s 667ms/step - loss: 1.3640e-05\n",
            "comp: COST mse: 0.10648022929305717 norm_mse: 0.16602740547867137\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 30s 665ms/step - loss: 0.0206\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 7s 663ms/step - loss: 0.0033\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 7s 670ms/step - loss: 0.0011\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 7s 667ms/step - loss: 6.3005e-04\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 7s 669ms/step - loss: 4.7204e-04\n",
            "comp: FB mse: 0.03685422792744994 norm_mse: 0.04179354450071826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP31xOCIzbUj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}